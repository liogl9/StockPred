{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "from datasetsplit import *\n",
    "from architectures import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Setup complete. Using torch {torch.__version__}({device})\")\n",
    "torch.manual_seed(123)\n",
    "lookback = 5*24\n",
    "PATH = os.path.join(os.getcwd(),\"models\",\"{}daysLoopback\".format(lookback),\"btc1y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = yf.Ticker(\"BTC-USD\")\n",
    "# historico_btc = btc.history()\n",
    "# Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "historico_btc = yf.download(tickers = \"BTC-USD\", start=\"2023-07-01\",end=\"2023-11-19\",interval=\"1h\")\n",
    "historico_eth = yf.download(tickers = \"ETH-USD\", start=\"2023-07-01\",end=\"2023-11-19\",interval=\"1h\")\n",
    "historico_btc.drop(historico_btc.tail(1).index,inplace=True)\n",
    "historico_btc.drop(columns=[\"Volume\",\"Adj Close\"],inplace=True)\n",
    "print(historico_btc.min())\n",
    "print(max(historico_btc.High))\n",
    "print(min(historico_btc.Low))\n",
    "historico_btc = (historico_btc-min(historico_btc.Low))*10/(max(historico_btc.High)-min(historico_btc.Low))\n",
    "historico_eth = (historico_eth-min(historico_eth.Low))*10/(max(historico_eth.High)-min(historico_eth.Low))\n",
    "historico_btc[\"Eth_close\"] = historico_eth.Close\n",
    "historico_btc[\"RSI\"] = ta.rsi(historico_btc.Close, length=14)\n",
    "historico_btc[\"MACD\"] = ta.ema(historico_btc.Close, length=12)-ta.ema(historico_btc.Close, length=26)\n",
    "historico_btc[\"Signal\"] = ta.ema(historico_btc.MACD, length=9)\n",
    "historico_btc[\"CloseVar\"] = historico_btc[\"Close\"].diff()\n",
    "historico_btc['CloseVar'] = historico_btc['CloseVar'].clip(upper=0.25,lower=-0.25)\n",
    "historico_btc.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the close Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_btc[\"Target\"] = historico_btc.Close[1:]\n",
    "cleandf = historico_btc.drop(columns=[\"Volume\",\"Adj Close\"])\n",
    "cleandf.Target = cleandf.Target.shift(-1)\n",
    "cleandf.dropna(inplace=True)\n",
    "cleandf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_np = cleandf.values.astype('float32')\n",
    "# close_var = close_var.reshape((-1,1))\n",
    "data_shape = full_np.shape\n",
    "print(full_np.shape)\n",
    "plt.plot(full_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_list = []\n",
    "scaled_data = np.ones_like(full_np)\n",
    "for column in range(data_shape[1]):\n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "    full_min = full_np[:,column].min()\n",
    "    full_max = full_np[:,column].max()\n",
    "    scaler_list.append(MinMaxScaler(feature_range=(full_min, full_max)))\n",
    "    # if column == 4:\n",
    "    #     scaled_data[:,column] = full_np[:,column]\n",
    "    # else:\n",
    "    scaled_data[:,column] = sc.fit_transform(full_np[:,column].reshape(-1,1)).reshape(-1,)\n",
    "    # training_set_scaled = close_var\n",
    "    print(\"Column: \", column)\n",
    "    print(\"Min: \", full_min)\n",
    "    print(\"Max: \", full_max)\n",
    "    plt.plot(scaled_data[:,column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTMOnlyLast(20,1,0).to(device)\n",
    "model = LSTMLastOutput(data_shape[1]-1,15,1,0).to(device)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-val split for time series\n",
    "train_size = int(len(scaled_data[:,0]) * 0.67)\n",
    "val_size = len(scaled_data[:,0])  - train_size\n",
    "train, val = scaled_data[:train_size,:], scaled_data[train_size:]\n",
    "if isinstance(model,LSTMLastOutput):\n",
    "    X_train, y_train = create_dataset_one_output(train, lookback=lookback)\n",
    "    X_val, y_val = create_dataset_one_output(val, lookback=lookback)\n",
    "\n",
    "print(\"Input train size: \", X_train.shape,\"; Output train size: \", y_train.shape)\n",
    "print(\"Input val size: \", X_val.shape,\"; Output val size: \", y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
    "loss_fn = nn.MSELoss()\n",
    "train_loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=False, batch_size=256)\n",
    "n_epochs = 20000\n",
    "best_loss = 100\n",
    "output_length = scaled_data.shape[0]\n",
    "y_full_preds = np.ones((output_length-lookback,1))*np.nan\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    # y_pred_train = torch.zeros_like(y_train)\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Validation\n",
    "    if epoch % 100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_train_gpu = X_train.to(device)\n",
    "            y_pred_train = model(X_train_gpu)\n",
    "            train_rmse = np.sqrt(loss_fn(y_pred_train.cpu(), y_train))\n",
    "\n",
    "            X_val_gpu = X_val.to(device)\n",
    "            y_pred_val = model(X_val_gpu)\n",
    "            val_rmse = np.sqrt(loss_fn(y_pred_val.cpu(), y_val))\n",
    "\n",
    "            # shift train predictions for plotting\n",
    "            train_plot = np.ones_like(scaled_data[:,-1]) * np.nan\n",
    "            train_plot[lookback:train_size] = y_pred_train.cpu()[:, -1, :].squeeze(1)\n",
    "            # train_plot[lookback:train_size] = sc_train.fit_transform(y_pred_train.cpu()[:, -1, :])\n",
    "\n",
    "            # shift val predictions for plotting\n",
    "            val_plot = np.ones_like(scaled_data[:,-1]) * np.nan\n",
    "            val_plot[train_size+lookback:len(scaled_data[:,-1])] = y_pred_val.cpu()[:, -1, :].squeeze(1)\n",
    "            # val_plot[train_size+lookback:len(scaled_data)] = sc_val.fit_transform(y_pred_val.cpu()[:, -1, :])\n",
    "            \n",
    "            # plot\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(scaled_data[:,-1], c='b')\n",
    "            ax.plot(train_plot, c='r')\n",
    "            ax.plot(val_plot, c='g')\n",
    "            start, end = ax.get_xlim()\n",
    "            ax.xaxis.set_ticks(np.arange(0, end, 30*24))\n",
    "            ax.grid()\n",
    "            if val_rmse < best_loss:\n",
    "                best_loss = val_rmse\n",
    "                try:\n",
    "                    torch.save(model.state_dict(), os.path.join(PATH,\"best_model.pt\"))\n",
    "                    plt.savefig(os.path.join(PATH,\"result.png\"))\n",
    "                except:\n",
    "                    os.makedirs(PATH)\n",
    "                    torch.save(model.state_dict(), os.path.join(PATH,\"best_model.pt\"))\n",
    "                    plt.savefig(os.path.join(PATH,\"result.png\"))\n",
    "\n",
    "                print(\"New Best model saved\")\n",
    "            # plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        print(\"Epoch %d: train RMSE %.6f, val RMSE %.6f, best val %.6f\" % (epoch, train_rmse, val_rmse, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(scaled_data[:,-1], c='b')\n",
    "ax.plot(train_plot, c='r')\n",
    "ax.plot(val_plot, c='g')\n",
    "# ax.plot(full_test_plot,c='m')\n",
    "start, end = ax.get_xlim()\n",
    "# ax.xaxis.set_ticks(np.arange(0, end, 1))\n",
    "# ax.yaxis.set_ticks(np.arange(0, 1, 0.05))\n",
    "ax.grid()\n",
    "plt.xlim(5700,5900)\n",
    "plt.ylim(0.6,0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PredicciÃ³n de valores futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = yf.Ticker(\"BTC-USD\")\n",
    "historico_btc = btc.history(period=\"5y\")\n",
    "close_price = historico_btc.iloc[:,1:2].values.astype('float32')\n",
    "close_price = close_price.reshape((-1,1))\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "test_set_scaled = sc.fit_transform(close_price)\n",
    "model = LSTMOnlyLast(20,1,0).to(device)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(test_set_scaled) * 0.67)\n",
    "val_size = len(test_set_scaled) - train_size\n",
    "train, val = test_set_scaled[:train_size], test_set_scaled[train_size:]\n",
    "test = test_set_scaled[-lookback-1:]\n",
    "\n",
    "lookback = 30\n",
    "\n",
    "if isinstance(model,LSTMOnlyLast):\n",
    "    X_val, y_val = create_dataset_one_output(val, lookback=lookback)\n",
    "    X_full, y_full = create_single_sample(train, lookback=lookback)\n",
    "    X_test = create_testset(test, lookback=lookback)\n",
    "\n",
    "elif isinstance(model, LSTMWhole):\n",
    "    X_val, y_val = create_dataset_whole_output(val, lookback=lookback)\n",
    "    X_full, y_full = create_single_sample(train, lookback=lookback)\n",
    "    X_test = create_testset(test, lookback=lookback)\n",
    "\n",
    "\n",
    "val_min = close_price[train_size:,:].min()\n",
    "val_max = close_price[train_size:,:].max()\n",
    "sc_val = MinMaxScaler(feature_range=(val_min, val_max))\n",
    "print(X_test.shape)\n",
    "test_min = close_price[-lookback:,:].min()\n",
    "test_max = close_price[-lookback:,:].max()\n",
    "sc_test = MinMaxScaler(feature_range=(test_min, test_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 300\n",
    "model_path = PATH = os.path.join(os.getcwd(),\"models\",\"{}daysLoopback\".format(lookback),\"btc5y\", \"best_model.pt\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "n_preds = 31\n",
    "y_preds = np.ones((n_preds,1))*np.nan\n",
    "y_val_preds = np.ones((val_size-lookback,1))*np.nan\n",
    "y_full_preds = np.ones((test_set_scaled.shape[0]-lookback,1))*np.nan\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_val_gpu = X_val.to(device)\n",
    "    y_pred_val = model(X_val_gpu)\n",
    "    val_plot = np.ones_like(test_set_scaled) * np.nan\n",
    "    val_plot[train_size+lookback:len(test_set_scaled)] = y_pred_val.cpu()[:, -1, :]\n",
    "    for pred in range(test_set_scaled.shape[0]-lookback):\n",
    "        X_full_gpu = X_full.to(device)\n",
    "        y_pred_full = model(X_full_gpu)\n",
    "        y_full_preds[pred,:] = y_pred_full.cpu()[:, -1, :]\n",
    "        new_input = np.ones_like(X_full.numpy())\n",
    "        new_input[:,:-1,:] = X_full.numpy()[:,1:,:]\n",
    "        new_input[:,-1,:] = y_pred_full.cpu()[:, -1, :]\n",
    "        X_full = torch.tensor(new_input)\n",
    "        full_test_plot = np.ones((test_set_scaled.shape[0],1)) * np.nan\n",
    "        full_test_plot[lookback:] = y_full_preds.reshape(-1,1)\n",
    "    for n_pred in range(n_preds):\n",
    "        X_test_gpu = X_test.to(device)\n",
    "        y_pred_test = model(X_test_gpu)\n",
    "        y_preds[n_pred,:] = y_pred_test.cpu()[:, -1, :]\n",
    "        new_input = np.ones_like(X_test.numpy())\n",
    "        new_input[:,:-1,:] = X_test.numpy()[:,1:,:]\n",
    "        new_input[:,-1,:] = y_pred_test.cpu()[:, -1, :]\n",
    "        X_test = torch.tensor(new_input)\n",
    "        test_plot = np.ones((test_set_scaled.shape[0]+n_preds,1)) * np.nan\n",
    "        test_plot[len(test_set_scaled):len(test_set_scaled)+n_preds] = y_preds.reshape(-1,1)\n",
    "        # plot\n",
    "plt.plot(test_set_scaled, c='b')\n",
    "plt.plot(val_plot,c='g')\n",
    "plt.plot(test_plot, c='g')\n",
    "plt.plot(full_test_plot,c='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_set_scaled, c='b')\n",
    "plt.plot(val_plot,c='g')\n",
    "plt.plot(test_plot, c='g')\n",
    "plt.xlim((500,600))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the variation of the close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_btc[\"Target\"] = historico_btc[\"CloseVar\"]\n",
    "historico_btc.Target=historico_btc.Target.shift(-1)\n",
    "historico_btc.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf=historico_btc\n",
    "cleandf.dropna(inplace=True)\n",
    "cleandf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_np = cleandf.values.astype('float32')\n",
    "# close_var = close_var.reshape((-1,1))\n",
    "data_shape = full_np.shape\n",
    "print(full_np.shape)\n",
    "plt.plot(full_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = full_np.shape\n",
    "print(full_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_list = []\n",
    "# scaled_data = np.ones_like(full_np)\n",
    "# for column in range(data_shape[1]):\n",
    "#     sc = MinMaxScaler(feature_range=(0,100))\n",
    "#     full_min = full_np[:,column].min()\n",
    "#     full_max = full_np[:,column].max()\n",
    "#     scaler_list.append(MinMaxScaler(feature_range=(full_min, full_max)))\n",
    "#     if column in [4,5,6]:\n",
    "#         scaled_data[:,column] = full_np[:,column]\n",
    "#     else:\n",
    "#         scaled_data[:,column] = sc.fit_transform(full_np[:,column].reshape(-1,1)).reshape(-1,)\n",
    "#     # training_set_scaled = close_var\n",
    "#     print(\"Column: \", column)\n",
    "#     print(\"Min: \", full_min)\n",
    "#     print(\"Max: \", full_max)\n",
    "#     plt.plot(scaled_data[:,column])\n",
    "#     plt.show()\n",
    "scaled_data = full_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LSTMLastOutput(9,50,1,0).to(device)\n",
    "# model = LSTMMultiInputSingleOutput(4,10,1,0).to(device)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train-val split for time series\n",
    "train_size = int(len(scaled_data[:,0]) * 0.8)\n",
    "val_size = len(scaled_data[:,0])  - train_size\n",
    "train, val = scaled_data[:train_size,:], scaled_data[train_size:]\n",
    "if isinstance(model,LSTMLastOutput):\n",
    "    X_train, y_train = create_dataset_one_output(train, lookback=lookback)\n",
    "    X_val, y_val = create_dataset_one_output(val, lookback=lookback)\n",
    "train_loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=False, batch_size=256)\n",
    "val_loader = data.DataLoader(data.TensorDataset(X_val, y_val), shuffle=False, batch_size=256)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5316/20000 [1:18:47<3:49:46,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5315: train RMSE 0.000175, val RMSE 0.173506, best val 0.000175, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5321/20000 [1:18:51<3:31:37,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5320: train RMSE 0.000418, val RMSE 0.173804, best val 0.000175, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5326/20000 [1:18:55<3:43:53,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5325: train RMSE 0.000175, val RMSE 0.173591, best val 0.000175, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5331/20000 [1:18:59<3:32:11,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5330: train RMSE 0.000419, val RMSE 0.173890, best val 0.000175, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5336/20000 [1:19:04<3:42:40,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5335: train RMSE 0.000175, val RMSE 0.173677, best val 0.000175, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5341/20000 [1:19:08<3:24:22,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5340: train RMSE 0.000419, val RMSE 0.173975, best val 0.000175, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5346/20000 [1:19:12<3:40:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5345: train RMSE 0.000174, val RMSE 0.173762, best val 0.000174, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5351/20000 [1:19:16<3:21:33,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5350: train RMSE 0.000419, val RMSE 0.174060, best val 0.000174, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5356/20000 [1:19:20<3:25:58,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5355: train RMSE 0.000174, val RMSE 0.173846, best val 0.000174, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5361/20000 [1:19:24<3:19:38,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5360: train RMSE 0.000419, val RMSE 0.174144, best val 0.000174, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5366/20000 [1:19:29<3:35:57,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5365: train RMSE 0.000173, val RMSE 0.173930, best val 0.000173, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5371/20000 [1:19:33<3:28:24,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5370: train RMSE 0.000420, val RMSE 0.174228, best val 0.000173, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5376/20000 [1:19:37<3:25:30,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5375: train RMSE 0.000173, val RMSE 0.174014, best val 0.000173, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5381/20000 [1:19:41<3:21:15,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5380: train RMSE 0.000420, val RMSE 0.174311, best val 0.000173, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5386/20000 [1:19:45<3:37:49,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5385: train RMSE 0.000172, val RMSE 0.174096, best val 0.000172, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5391/20000 [1:19:49<3:27:24,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5390: train RMSE 0.000420, val RMSE 0.174394, best val 0.000172, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5396/20000 [1:19:54<3:39:06,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best model saved\n",
      "Epoch 5395: train RMSE 0.000172, val RMSE 0.174178, best val 0.000172, Lr: 0.0000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|âââ       | 5397/20000 [1:19:55<3:36:14,  1.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lio\\Desktop\\Stock\\StockPred\\btclstm.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lio/Desktop/Stock/StockPred/btclstm.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(loss_fn(y_pred, y_batch))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lio/Desktop/Stock/StockPred/btclstm.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lio/Desktop/Stock/StockPred/btclstm.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lio/Desktop/Stock/StockPred/btclstm.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lio/Desktop/Stock/StockPred/btclstm.ipynb#X32sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_rmse \u001b[39m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\Lio\\miniconda3\\envs\\stockpred\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lio\\miniconda3\\envs\\stockpred\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',0.5,40,0.000001, verbose=True)\n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 20000\n",
    "best_loss = 100\n",
    "output_length = scaled_data.shape[0]\n",
    "y_full_preds = np.ones((output_length-lookback,1))*np.nan\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    train_plot = np.ones_like(scaled_data[:,-1]) * np.nan\n",
    "    y_pred_train = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        loss = torch.sqrt(loss_fn(y_pred, y_batch))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_rmse = loss\n",
    "        y_pred_train.extend(y_pred.cpu().detach()[:, -1, :].squeeze().tolist())\n",
    "    train_plot[lookback:train_size] = y_pred_train\n",
    "    scheduler.step(train_rmse)\n",
    "    # Validation\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_plot = np.ones_like(scaled_data[:,-1]) * np.nan\n",
    "            y_pred_val = []\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                loss = torch.sqrt(loss_fn(y_pred, y_batch))\n",
    "                val_rmse = loss\n",
    "                y_pred_val.extend(y_pred.cpu().detach()[:, -1, :].squeeze().tolist())\n",
    "            val_plot[train_size+lookback:] = y_pred_val\n",
    "            \n",
    "            # plot\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(scaled_data[:,-1], c='b')\n",
    "            ax.plot(train_plot, c='r')\n",
    "            ax.plot(val_plot, c='g')\n",
    "            start, end = ax.get_xlim()\n",
    "            # ax.xaxis.set_ticks(np.arange(0, end, 30*24))\n",
    "            ax.grid()\n",
    "            if train_rmse<best_loss:\n",
    "                best_loss = train_rmse\n",
    "                try:\n",
    "                    torch.save(model.state_dict(), os.path.join(PATH,\"best_model.pt\"))\n",
    "                    plt.savefig(os.path.join(PATH,\"result.png\"))\n",
    "                except:\n",
    "                    os.makedirs(PATH)\n",
    "                    torch.save(model.state_dict(), os.path.join(PATH,\"best_model.pt\"))\n",
    "                    plt.savefig(os.path.join(PATH,\"result.png\"))\n",
    "\n",
    "                print(\"New Best model saved\")\n",
    "            # plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "\n",
    "        print(\"Epoch %d: train RMSE %.6f, val RMSE %.6f, best val %.6f, Lr: %.7f\" % (epoch, train_rmse,  val_rmse, best_loss, optimizer.param_groups[0][\"lr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_plot = np.ones_like(scaled_data[:,-1]) * np.nan\n",
    "    y_pred_train = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        loss = torch.sqrt(loss_fn(y_pred, y_batch))\n",
    "        train_rmse = loss\n",
    "        y_pred_train.extend(y_pred.cpu().detach()[:, -1, :].squeeze().tolist())\n",
    "    train_plot[lookback:train_size] = y_pred_train\n",
    "    val_plot = np.ones_like(scaled_data[:,-1]) * np.nan\n",
    "    y_pred_val = []\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        loss = torch.sqrt(loss_fn(y_pred, y_batch))\n",
    "        val_rmse = loss\n",
    "        y_pred_val.extend(y_pred.cpu().detach()[:, -1, :].squeeze().tolist())\n",
    "    val_plot[train_size+lookback:] = y_pred_val\n",
    "\n",
    "last_data=X_train[-2:,:,:]\n",
    "with torch.no_grad():\n",
    "    pred = model(last_data)\n",
    "    print(pred)\n",
    "    \n",
    "last_sample = last_data\n",
    "last_sample[-2,:,:] = last_data[-1,:,:]\n",
    "last_sample[-1,:-1,:]=last_data[-1,-1:,:]\n",
    "last_sample[-1,-1,:] = torch.tensor(historico_btc.tail(1).values.astype('float32')[:,:-1])\n",
    "test_loader = data.DataLoader(data.TensorDataset(last_sample), shuffle=False, batch_size=1)\n",
    "test_plot = np.ones([scaled_data[:,-1].shape[0]+1,1]) * np.nan\n",
    "y_pred_test = []\n",
    "for X_batch in test_loader:\n",
    "    X_batch=X_batch[0]\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_pred = model(X_batch)\n",
    "    y_pred_test.extend(y_pred.cpu().detach().tolist())\n",
    "test_plot[-2:] = [y_pred_test[0][0],y_pred_test[1][0]]\n",
    "print(y_pred_train[-2:])\n",
    "print(y_pred_test)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(scaled_data[:,-1], c='b')\n",
    "ax.plot(train_plot, c='r')\n",
    "ax.plot(val_plot, c='g')\n",
    "ax.plot(test_plot, c='m')\n",
    "# ax.plot(full_test_plot,c='m')\n",
    "start, end = ax.get_xlim()\n",
    "# ax.xaxis.set_ticks(np.arange(0, end, 3))\n",
    "# ax.yaxis.set_ticks(np.arange(0, 1, 0.05))\n",
    "ax.grid()\n",
    "plt.xlim(2170,2200)\n",
    "# plt.ylim(20000,40000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
